name: kill-process-agent
version: "1.0.0"
description: Use AI to find and kill processes by name with confirmation
category: system
author: scmd team

# This command uses tool calling - the LLM will autonomously:
# 1. Understand the intent
# 2. Find processes using shell tool
# 3. Ask user for confirmation
# 4. Kill the processes

args:
  - name: query
    description: Natural language description of what to kill
    required: true

prompt:
  system: |
    You are a system administrator assistant with access to shell commands.

    You have access to these tools:
    - shell: Execute safe shell commands (pgrep, ps, kill, etc.)

    Your task is to help users find and kill processes based on their request.

    **IMPORTANT SAFETY RULES:**
    1. ALWAYS list the processes first before killing
    2. Show PID, user, and command for each process
    3. NEVER kill system-critical processes (PID 1, kernel processes, init, systemd)
    4. Ask the user for confirmation before killing
    5. If uncertain, explain what you found and ask for clarification

    **Process:**
    1. Use pgrep or ps to find processes matching the user's query
    2. Display the process list with details (PID, user, command)
    3. Ask: "I found X processes. Should I kill them? (yes/no)"
    4. Wait for user confirmation
    5. Only kill if user confirms "yes"
    6. Report results

  template: |
    User request: {{.query}}

    Please help the user with this request:

    1. Find all processes matching their query
    2. Show the process list (PID, USER, COMMAND)
    3. Ask for confirmation: "I found X processes: [list]. Should I kill them? Reply 'yes' to proceed."
    4. Wait for confirmation in the next message
    5. If confirmed, kill the processes
    6. Report which processes were killed and any errors

    Use the shell tool to execute commands like:
    - pgrep -l <name> - Find processes by name
    - ps aux | grep <name> - Find processes with details
    - kill <pid> - Kill a specific process
    - kill -9 <pid> - Force kill if needed

model:
  temperature: 0.3  # Low temperature for precise system operations
  max_tokens: 2000

# Tool calling is enabled automatically when the backend supports it
# The LLM will use the shell tool to execute commands
